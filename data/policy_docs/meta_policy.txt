Meta’s hate speech policy strictly prohibits any content that attacks individuals or groups based on protected characteristics such as race, ethnicity, national origin, religious affiliation, sexual orientation, sex, gender, gender identity, or serious disability. The platform enforces a zero-tolerance approach to speech that dehumanizes or degrades individuals by portraying them as sub-human, inferior, or using harmful comparisons such as calling people “vermin” or “disease.” It also disallows content that perpetuates negative stereotypes or incites fear and distrust against these groups.

In addition, Meta does not permit content that includes threats of violence, whether direct or implicit, as well as any advocacy for exclusion, segregation, or systemic discrimination. This includes statements that call for the social, political, or economic isolation of a protected group, or that suggest they should be denied rights or equal treatment. Meta’s policy also covers veiled or coded language if it functions to promote hatred or reinforce discriminatory ideologies.

The policy is enforced across all Meta platforms, including Facebook and Instagram, and violations can lead to content removal, temporary restrictions, or permanent account suspension. Meta also provides reporting tools for users to flag hate speech and has internal moderation systems—both human and automated—to review and respond to harmful content. Through these measures, Meta aims to foster safe and inclusive communities while balancing freedom of expression with the need to protect individuals from targeted abuse and hate.
